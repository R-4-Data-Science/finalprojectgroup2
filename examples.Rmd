---
title: "examples"
output: html_document
date: "2025-12-02"
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Install from GitHub if not already installed
# Comment/Uncomment next two lines as needed
#install.packages("devtools")
devtools::install_github("R-4-Data-Science/finalprojectgroup2")

# Load the package
library(finalprojectgroup2)

library(reshape2)
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
```


## 5.1 - Gaussian Linear Regression

```{r}
## 5.1 Linear regression (Gaussian) — using package functions

set.seed(5)
n <- 120; p <- 8
X <- matrix(rnorm(n * p), n, p)
beta <- c(2, -1.5, 0, 0, 1, rep(0, p - 5))
y <- as.numeric(X %*% beta + rnorm(n, sd = 1))
colnames(X) <- paste0("x", 1:p)

# 1. Multi-path forward selection on the full data
forest <- build_paths(
  X      = X,
  y      = y,
  family = "gaussian",
  K      = min(p, 10),
  eps    = 1e-6,
  delta  = 10,
  L      = 50
)

# Inspect the best few models by AIC
head(forest$aic_by_model[order(forest$aic_by_model$aic), ], 5)

# 2. Stability via bootstrap resampling
stab <- stability(
  X             = X,
  y             = y,
  family        = "gaussian",
  B             = 50,
  resample_type = "bootstrap",
  K             = min(p, 10),
  eps           = 1e-6,
  delta         = 10,
  L             = 50
)

# Variable-wise stability scores π_j
stab$pi

# 3. Plausible models: low AIC and high average stability
plaus <- plausible_models(
  forest = forest,
  stab   = stab,
  Delta  = 10,
  tau    = 0.6
)

plaus # plausible model object

# 4. Extra: create a heatmap of strength of each predictor in plausible models
# This heatmap will display a visual representation of each predictor's influence on an individual model.
# The darker the color, the more relative influence a predictor has.
# Much lighter colors indicate the predictor is present, but has little influence.
# Blank colors indicate the predictor is not present in the model.

p <- length(stab$pi)
m <- nrow(plaus)

strength_mat <- matrix(0, nrow = p, ncol = m)

for (k in seq_len(m)) {
  vars_k <- plaus$vars[[k]]          # predictor indices in model k
  strength_mat[vars_k, k] <- stab$pi[vars_k]
}

rownames(strength_mat) <- paste0("X", seq_len(p))
colnames(strength_mat) <- paste0("M", seq_len(m))

rel_strength_mat <- apply(
  strength_mat,
  2,   # per model (per column)
  function(col) {
    s <- sum(col)                  # sum of included predictors' stabilities
    if (s == 0) col else col / s   # divide by sum, not by max
  }
)

rel_strength_mat <- t(rel_strength_mat) # transposing so row and columns are flipped

df_long <- melt(rel_strength_mat, varnames = c("model", "predictor"), value.name = "strength")


ggplot(df_long, aes(x = predictor, y = model, fill = strength)) +
  geom_tile() +
  scale_fill_gradient(low = "black", high = "green", limits = c(0, 0.5)) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5),
    panel.grid = element_blank()
  ) +
  labs(
    x = "Predictor",
    y = "Plausible Model",
    fill = "Relative\nStrength"
  )


```


## 5.2 - Binomial Logistic Regression
```{r example-5-2-binomial, message=FALSE}
set.seed(10)

## Simulate a logistic regression dataset
n <- 200
p <- 8

X <- matrix(rnorm(n * p), n, p)
colnames(X) <- paste0("x", 1:p)

beta <- c(1.5, -1.0, 0.8, 0, 0, 0, 0, 0)
eta  <- X %*% beta
prob <- 1 / (1 + exp(-eta))  # plogis(eta)

y <- rbinom(n, size = 1, prob = prob)

## 1. Multi-path forward selection on full data (binomial family)
forest_bin <- build_paths(
  X      = X,
  y      = y,
  family = "binomial",
  K      = min(p, 10),
  eps    = 1e-6,
  delta  = 10,
  L      = 50
)

# Best few models by AIC
head(forest_bin$aic_by_model[order(forest_bin$aic_by_model$aic), ], 5)

## 2. Stability via bootstrap resampling
stab_bin <- stability(
  X             = X,
  y             = y,
  family        = "binomial",
  B             = 30,        # keep modest for knitting speed
  resample_type = "bootstrap",
  K             = min(p, 10),
  eps           = 1e-6,
  delta         = 10,
  L             = 50
)

# Variable-wise stability scores π_j
stab_bin$pi

## 3. Plausible models: AIC window + stability threshold
plaus_bin <- plausible_models(
  forest = forest_bin,
  stab   = stab_bin,
  Delta  = 10,
  tau    = 0.5
)

plaus_bin

# Extra: create a heatmap of strength of each predictor in plausible models
# This heatmap will display a visual representation of each predictor's influence on an individual model.
# The darker the color, the more relative influence a predictor has.
# Much lighter colors indicate the predictor is present, but has little influence.
# Blank colors indicate the predictor is not present in the model.

p <- length(stab_bin$pi)
m <- nrow(plaus_bin)

strength_mat <- matrix(0, nrow = p, ncol = m)

for (k in seq_len(m)) {
  vars_k <- plaus_bin$vars[[k]]          # predictor indices in model k
  strength_mat[vars_k, k] <- stab_bin$pi[vars_k]
}

rownames(strength_mat) <- paste0("X", seq_len(p))
colnames(strength_mat) <- paste0("M", seq_len(m))

rel_strength_mat <- apply(
  strength_mat,
  2,   # per model (per column)
  function(col) {
    s <- sum(col)                  # sum of included predictors' stabilities
    if (s == 0) col else col / s   # divide by sum, not by max
  }
)

rel_strength_mat <- t(rel_strength_mat) # transposing so row and columns are flipped

df_long <- melt(rel_strength_mat, varnames = c("model", "predictor"), value.name = "strength")


ggplot(df_long, aes(x = predictor, y = model, fill = strength)) +
  geom_tile() +
  scale_fill_gradient(low = "black", high = "green", limits = c(0, 0.5)) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5),
    panel.grid = element_blank()
  ) +
  labs(
    x = "Predictor",
    y = "Plausible Model",
    fill = "Relative\nStrength"
  )


## 4. If there is at least one plausible model, fit it and compute confusion metrics
if (nrow(plaus_bin) > 0) {
  # Take the best plausible model (lowest AIC)
  best_idx   <- which.min(plaus_bin$aic)
  vars_best  <- plaus_bin$vars[[best_idx]]

  X_df <- as.data.frame(X)
  y_df <- as.numeric(y)

  if (length(vars_best) == 0L) {
    # Empty model: intercept-only logistic regression
    form_best <- y_df ~ 1
  } else {
    var_names <- colnames(X_df)[vars_best]
    form_best <- as.formula(
      paste("y_df ~", paste(var_names, collapse = " + "))
    )
  }

  fit_best <- glm(
    formula = form_best,
    data    = X_df,
    family  = binomial()
  )

  p_hat <- predict(fit_best, type = "response")

  cm <- confusion_metrics(y_true = y_df, p_hat = p_hat, cutoff = 0.5)

  cm$confusion
  cm$metrics
}
```
